{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":92039,"databundleVersionId":10998020,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:02:06.360947Z","iopub.execute_input":"2025-02-27T09:02:06.361327Z","iopub.status.idle":"2025-02-27T09:02:06.370515Z","shell.execute_reply.started":"2025-02-27T09:02:06.361285Z","shell.execute_reply":"2025-02-27T09:02:06.369229Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/1dl034-project-vt25/sample_submission.csv\n/kaggle/input/1dl034-project-vt25/taxi_zone_lookup.csv\n/kaggle/input/1dl034-project-vt25/training_dataset.csv\n/kaggle/input/1dl034-project-vt25/evaluation_dataset.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.metrics import r2_score, accuracy_score #, root_mean_squared_log_error\n#from pyspark.sql import SparkSession\nimport pandas as pd\nfrom pandas.api.types import is_numeric_dtype as is_num\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:05:49.325962Z","iopub.execute_input":"2025-02-27T09:05:49.326397Z","iopub.status.idle":"2025-02-27T09:05:49.332692Z","shell.execute_reply.started":"2025-02-27T09:05:49.326365Z","shell.execute_reply":"2025-02-27T09:05:49.331420Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# spark = SparkSession.builder.appName(\"AIProject\").config(\"spark.driver.memory\", \"4g\").getOrCreate()\n# data_frame = spark.read.csv('/kaggle/input/1dl034-project-vt25/training_dataset.csv', header=True, inferSchema=True)\n# df = data_frame.limit(50000).toPandas()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/1dl034-project-vt25/training_dataset.csv', nrows=50000)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.dropna()\n\ndf['store_and_fwd_flag'] = df['store_and_fwd_flag'].replace(['N', 'Y'], [1, 2])\n\ndf = df.drop('ID', axis=1)\ndf = df.drop('vendorid', axis=1)\ndf = df.drop('tpep_pickup_datetime', axis=1)\ndf = df.drop('tpep_dropoff_datetime', axis=1)\n\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_columns = [\n    \"passenger_count\", \"trip_distance\", \"pulocationid\", \"dolocationid\",\n    \"ratecodeid\", \"fare_amount\", \"extra\", \"mta_tax\", \"improvement_surcharge\",\n    \"tip_amount\", \"tolls_amount\", \"total_amount\", \"congestion_surcharge\", \"airport_fee\", \"duration\"\n]\n\nfor col in numeric_columns:\n    assert is_num(df[col])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = df.iloc[:, :-1]\ny = df[\"duration\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lin_mod = LinearRegression()\n\nlin_mod.fit(x_train, y_train)\n\ny_pred_lin_mod = lin_mod.predict(x_test)\n\nprint(r2_score(y_test, y_pred_lin_mod))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_cv = 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TODO: Fix, did not converge\n# maybe increase number of iterations\n# 4 min 12 sec\nlog_mod = LogisticRegression(max_iter=200)\n\nlog_mod.fit(x_train, y_train)\n\ny_pred_log_mod = log_mod.predict(x_test)\n\nprint(accuracy_score(y_test, y_pred_log_mod))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ranf_mod = RandomForestRegressor(random_state=42)\n\n# print(np.mean(cross_val_score(ranf_mod, x, y, cv=n_cv)))\nranf_mod.fit(x_train, y_train)\ny_pred_ranf = ranf_mod.predict(x_test)\n# ranf_mod.score(x_test, y_test)\n\nprint(r2_score(y_test, y_pred_ranf))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ranf_mod = RandomForestRegressor(random_state=42)\nranf_mod.fit(x_train, y_train)\n\ny_pred_ranf = ranf_mod.predict(x_test)\nprint(r2_score(y_test, y_pred_ranf))\n\n\nfeature_scores = pd.Series(ranf_mod.feature_importances_, index = x_train.columns).sort_values(ascending = False)\n\nimport seaborn as sns\nsns.barplot(x=feature_scores, y=feature_scores.index, )\nplt.title(\"Importance of each Feature for the Random Forest classifier\")\nplt.xlabel('Importance')\nplt.ylabel('Features')\nplt.show()\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Based on feature importance, features are removed.","metadata":{}},{"cell_type":"code","source":"\n\ndf = df.drop('store_and_fwd_flag', axis=1)\ndf = df.drop('airport_fee', axis=1)\ndf = df.drop('mta_tax', axis=1)\ndf = df.drop('tolls_amount', axis=1)\ndf = df.drop('improvement_surcharge', axis=1)\ndf = df.drop('congestion_surcharge', axis=1)\ndf = df.drop('ratecodeid', axis=1)\ndf = df.drop('passenger_count', axis=1)\n\nx = df.iloc[:, :-1]\ny = df[\"duration\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\nranf_mod = RandomForestRegressor(random_state=42)\nranf_mod.fit(x_train, y_train)\n\ny_pred_ranf = ranf_mod.predict(x_test)\nprint(r2_score(y_test, y_pred_ranf))\n\nfeature_scores = pd.Series(ranf_mod.feature_importances_, index = x_train.columns).sort_values(ascending = False)\n\nimport seaborn as sns\nsns.barplot(x=feature_scores, y=feature_scores.index, )\nplt.title(\"Importance of each Feature for the Random Forest classifier\")\nplt.xlabel('Importance')\nplt.ylabel('Features')\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.scatter(df['duration'], df['trip_distance'])\nscatter = sns.scatterplot(x='duration', y='trip_distance', data=df)\n#scatter.set_xlim(left= 0, right=7000)\n# sns.scatterplot(y='duration', x='trip_distance', data=df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_speed = 50\nmin_duration = 0\ncutoff_duration = 3000\n\n\ndf = df[(df['duration']) > min_duration]\ndf2 = df[(df['trip_distance'] / (df['duration'] / (60 * 60))) < max_speed] # 50 because 50 mph we set as max\ndf2 = df2.drop(df2[(df2['duration'] > cutoff_duration) & (df2['trip_distance'] / ((df2['duration'] - cutoff_duration) / (60*60)) < max_speed)].index)\n\nscatter = sns.scatterplot(x='duration', y='trip_distance', data=df2)\n#scatter.set_xlim(left= 0, right=7000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = df2.iloc[:, :-1]\ny = df2[\"duration\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\nranf_mod = RandomForestRegressor(random_state=42)\nranf_mod.fit(x_train, y_train)\n\ny_pred_ranf = ranf_mod.predict(x_test)\nprint(r2_score(y_test, y_pred_ranf))\n\nfeature_scores = pd.Series(ranf_mod.feature_importances_, index = x_train.columns).sort_values(ascending = False)\n\nimport seaborn as sns\nsns.barplot(x=feature_scores, y=feature_scores.index, )\nplt.title(\"Importance of each Feature for the Random Forest classifier\")\nplt.xlabel('Importance')\nplt.ylabel('Features')\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df2 = df2.drop('total_amount', axis=1)\n#df2 = df2.drop('dolocationid', axis=1)\n#df2 = df2.drop('pulocationid', axis=1)\n#df2 = df2.drop('extra', axis=1)\n#df2 = df2.drop('tip_amount', axis=1)\ndf2 = df2.drop('payment_type', axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nx = df2.iloc[:, :-1]\ny = df2[\"duration\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\nranf_mod = RandomForestRegressor(random_state=42)\nranf_mod.fit(x_train, y_train)\n\ny_pred_ranf = ranf_mod.predict(x_test)\nprint('r2', r2_score(y_test, y_pred_ranf))\nprint('log error', root_mean_squared_log_error(y_test, y_pred_ranf))\n\nfeature_scores = pd.Series(ranf_mod.feature_importances_, index = x_train.columns).sort_values(ascending = False)\n\nimport seaborn as sns\nsns.barplot(x=feature_scores, y=feature_scores.index, )\nplt.title(\"Importance of each Feature for the Random Forest classifier\")\nplt.xlabel('Importance')\nplt.ylabel('Features')\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svr_mod = SVR()\n\n# print(np.mean(cross_val_score(svr_mod, x, y, cv=n_cv)))\n\nsvr_mod.fit(x_train, y_train)\ny_pred_svr = svr_mod.predict(x_test)\n\n# print(svr_mod.score(x_test, y_test))\n\nprint(r2_score(y_test, y_pred_svr))\n\n#plt.scatter(y_test, y_pred_svr)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"linsvr_mod = LinearSVR(random_state=42)\n\n# print(np.mean(cross_val_score(linsvr_mod, x, y, cv=n_cv)))\n\nlinsvr_mod.fit(x_train, y_train)\n# y_pred_lin_svr = linsvr_mod.predict(x_test)\n\n# print(r2_score(y_test, y_pred_lin_svr))\n\nprint(linsvr_mod.score())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kneigh_mod = KNeighborsRegressor()\n\n# print(np.mean(cross_val_score(kneigh_mod, x, y, cv=n_cv)))\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tree_mod = DecisionTreeClassifier()\n\nprint(np.mean(cross_val_score(tree_mod, x, y, cv=n_cv)))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}